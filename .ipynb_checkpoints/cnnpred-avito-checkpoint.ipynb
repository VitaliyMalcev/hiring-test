{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pymystem3) (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pymystem3) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pymystem3) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pymystem3) (2.9)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pymystem3 import Mystem\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/testavito/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 53s, sys: 2min 57s, total: 14min 50s\n",
      "Wall time: 52min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text):\n",
    "    return m.lemmatize(text)\n",
    "#    return \"\".join(m.lemmatize(text))\n",
    "\n",
    "\n",
    "df['description'] = df['description'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделение выборки\n",
    "train, test = train_test_split(df, test_size = 0.1, random_state = 1234)\n",
    "\n",
    "print(\"Train 80%\", train.shape)\n",
    "print('Test 10%', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['is_bad']\n",
    "test_target = test['is_bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отчищаем память\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 44s, sys: 0 ns, total: 3min 44s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_words = 8000\n",
    "max_len = 350\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(train['description'])\n",
    "#трейн матрица\n",
    "sequences = tok.texts_to_sequences(train['description'])\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тест матрица\n",
    "test_sequences = tok.texts_to_sequences(test['description'])\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отчищаем память\n",
    "train = None\n",
    "#тест отсавляем, там категории для финальной метрики еще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(): #здорово и вечно\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 296,337\n",
      "Trainable params: 296,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5063/5063 [==============================] - 104s 20ms/step - loss: 0.2304 - accuracy: 0.9219 - val_loss: 0.1922 - val_accuracy: 0.9383\n",
      "Epoch 2/10\n",
      "5063/5063 [==============================] - 103s 20ms/step - loss: 0.1856 - accuracy: 0.9404 - val_loss: 0.1813 - val_accuracy: 0.9428\n",
      "Epoch 3/10\n",
      "5063/5063 [==============================] - 102s 20ms/step - loss: 0.1723 - accuracy: 0.9443 - val_loss: 0.1699 - val_accuracy: 0.9451\n",
      "Epoch 4/10\n",
      "5063/5063 [==============================] - 104s 21ms/step - loss: 0.1658 - accuracy: 0.9461 - val_loss: 0.1667 - val_accuracy: 0.9457\n",
      "Epoch 5/10\n",
      "5063/5063 [==============================] - 103s 20ms/step - loss: 0.1608 - accuracy: 0.9475 - val_loss: 0.1657 - val_accuracy: 0.9464\n",
      "Epoch 6/10\n",
      "5063/5063 [==============================] - 102s 20ms/step - loss: 0.1576 - accuracy: 0.9485 - val_loss: 0.1741 - val_accuracy: 0.9462\n",
      "Epoch 7/10\n",
      "5063/5063 [==============================] - 105s 21ms/step - loss: 0.1552 - accuracy: 0.9493 - val_loss: 0.1607 - val_accuracy: 0.9472\n",
      "Epoch 8/10\n",
      "5063/5063 [==============================] - 104s 21ms/step - loss: 0.1528 - accuracy: 0.9498 - val_loss: 0.1600 - val_accuracy: 0.9477\n",
      "Epoch 9/10\n",
      "5063/5063 [==============================] - 103s 20ms/step - loss: 0.1510 - accuracy: 0.9503 - val_loss: 0.1609 - val_accuracy: 0.9471\n",
      "Epoch 10/10\n",
      "5063/5063 [==============================] - 104s 20ms/step - loss: 0.1496 - accuracy: 0.9508 - val_loss: 0.1646 - val_accuracy: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa041ee9d10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,train_target,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001,patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\") # saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710264809988374"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# метрика по всем категориям\n",
    "test['pred'] = pred\n",
    "metric_list = []\n",
    "for i in test['category'].unique():\n",
    "    predictions = test[test['category']==i]['pred'].values\n",
    "    real = test[test['category']==i]['is_bad'].values\n",
    "    metric_list.append(roc_auc_score(real, predictions ))    \n",
    "print( pd.Series(metric_list).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
